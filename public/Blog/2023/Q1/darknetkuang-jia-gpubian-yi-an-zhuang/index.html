<!DOCTYPE html>
<html lang="en"  class="theme--light" >

<head>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css">
  <link href="https://fonts.googleapis.com/css2?family=Quicksand:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://king-key.github.io/style.css">
  <title>Wang Guo • darknet框架GPU编译安装</title>
  
  <link rel="alternate" type="application/rss+xml" title="Wang Guo" href="https://king-key.github.io/rss.xml">
  
  

  
  <script type="text/javascript" src="https://king-key.github.io/elasticlunr.min.js" defer></script>
  <script type="text/javascript" src="https://king-key.github.io/search_index.en.js" defer></script>
  
  <script type="text/javascript" src="https://king-key.github.io/js/search.js" defer></script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ["\\[", "\\]"]]
      },
      startup: {
        ready: () => {
          const prelist = document.getElementsByTagName("pre");
          const codelist = document.getElementsByTagName("code");
          const inline = MathJax.config.tex.inlineMath;
          const display = MathJax.config.tex.displayMath;
          const inlineRegexList = inline.map(delim => `(${delim[0].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&")})((.|[\\r\\n\\t])*?)(${delim[1].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&")})`);
          const displayRegexList = display.map(delim => `(${delim[0].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&")})((.|[\\r\\n\\t])*?)(${delim[1].replace(/[\-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&")})`);
          const inlineRegExp = new RegExp(inlineRegexList.join("|"));
          const displayRegExp = new RegExp(displayRegexList.join("|"));

          for (let i = prelist.length; i > 0; i--) {
            if (displayRegExp.test(prelist[i - 1].textContent)) {
              const t = document.createTextNode(prelist[i - 1].textContent);
              prelist[i - 1].parentNode.insertBefore(t, prelist[i - 1]);
              prelist[i - 1].parentNode.removeChild(prelist[i - 1]);
            }
          }

          for (let i = codelist.length; i > 0; i--) {
            if (inlineRegExp.test(codelist[i - 1].textContent)) {
              const t = document.createTextNode(codelist[i - 1].textContent);
              codelist[i - 1].parentNode.insertBefore(t, codelist[i - 1]);
              codelist[i - 1].parentNode.removeChild(codelist[i - 1]);
            }
          }

          MathJax.startup.defaultReady();
        }
      }
    };
  </script>
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      const menuButton = document.getElementById('menu-button');
      const sidebar = document.getElementById('sidebar');
      const mainContent = document.getElementById('main');
  
      menuButton.addEventListener('click', () => {
        sidebar.classList.toggle('active'); // 切换侧边栏显示状态
        mainContent.classList.toggle('active'); // 添加或移除遮罩效果
      });
  
      // 点击主内容区域时，隐藏侧边栏
      mainContent.addEventListener('click', () => {
        if (sidebar.classList.contains('active')) {
          sidebar.classList.remove('active');
          mainContent.classList.remove('active');
        }
      });
    });
  </script>
</head>

<body>
  <div id="sidebar" class="animated fadeInDown">
    <div class="logo-title">
      <div class="title">
        <div class="logo">
          <img src="https://king-key.github.io/images/logo.png" alt="Logo">
        </div>
        <h1><a href="https://king-key.github.io/">Wang Guo</a></h1>
        <div class="description">
          <p>王過</p>
        </div>
      </div>
    </div>
    <ul class="social-links">
      <li><a href="https://github.com/King-Key" aria-label="Go to Github profile page" title="Github"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true">   <path d="M12 0C5.37 0 0 5.37 0 12c0 5.3 3.438 9.8 8.205 11.385.6.113.82-.26.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61-.546-1.385-1.333-1.754-1.333-1.754-1.09-.745.083-.73.083-.73 1.205.085 1.84 1.237 1.84 1.237 1.07 1.835 2.807 1.305 3.492.997.108-.776.418-1.305.76-1.605-2.665-.3-5.466-1.333-5.466-5.932 0-1.31.47-2.38 1.235-3.22-.125-.303-.535-1.523.115-3.176 0 0 1.005-.322 3.3 1.23a11.5 11.5 0 0 1 3-.404c1.02.005 2.045.138 3 .404 2.28-1.552 3.285-1.23 3.285-1.23.655 1.653.245 2.873.12 3.176.77.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.628-5.475 5.922.43.37.815 1.103.815 2.222 0 1.606-.015 2.898-.015 3.293 0 .32.21.694.825.576C20.565 21.795 24 17.295 24 12c0-6.63-5.37-12-12-12z"/> </svg></a></li>
      <li><a href="https://twitter.com/WangGuo113" aria-label="Go to Twitter profile page" title="X"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="20" height="20" viewBox="0 0 50 50"> <path d="M 11 4 C 7.134 4 4 7.134 4 11 L 4 39 C 4 42.866 7.134 46 11 46 L 39 46 C 42.866 46 46 42.866 46 39 L 46 11 C 46 7.134 42.866 4 39 4 L 11 4 z M 13.085938 13 L 21.023438 13 L 26.660156 21.009766 L 33.5 13 L 36 13 L 27.789062 22.613281 L 37.914062 37 L 29.978516 37 L 23.4375 27.707031 L 15.5 37 L 13 37 L 22.308594 26.103516 L 13.085938 13 z M 16.914062 15 L 31.021484 35 L 34.085938 35 L 19.978516 15 L 16.914062 15 z"></path> </svg></a></li>
      <li><a class="link" href="https://www.xiaohongshu.com/user/profile/65a513af0000000003023abe" title="小红书"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="20" height="20" viewBox="0,0,256,256"> <g fill="#fa5252" fill-rule="nonzero" stroke="none" stroke-width="1" stroke-linecap="butt" stroke-linejoin="miter" stroke-miterlimit="10" stroke-dasharray="" stroke-dashoffset="0" font-family="none" font-weight="none" font-size="none" text-anchor="none" style="mix-blend-mode: normal"><g transform="scale(5.12,5.12)"><path d="M35,22v2h1v-2zM35,22v2h1v-2zM44,4h-38c-1.09,0 -2,0.91 -2,2v38c0,1.09 0.91,2 2,2h38c1.09,0 2,-0.91 2,-2v-38c0,-1.09 -0.91,-2 -2,-2zM12,24c0,1.38 -0.19,5.89 -2.61,6.24l-0.28,-1.98c0.39,-0.19 0.89,-2.14 0.89,-4.26v-2h2zM15,30h-2v-11h2zM17.29,29.71c-1.2,-1.2 -1.29,-4.73 -1.29,-5.78v-1.93h2v1.93c0,1.91 0.34,3.99 0.71,4.36zM22,31h-3l1,-2h3zM31,31h-7l1,-2h2v-7h-2l-2.1,4.38h1.72l-1,2h-2.62c-0.8,0 -1.28,-0.91 -0.82,-1.57l1.82,-2.81h-2c-0.78,0 -1.26,-0.85 -0.86,-1.51l3,-5l1.72,1.02l-2.09,3.49h3.23v-2h6v2h-2v7h2zM40,28.5c0,1.38 -1.12,2.5 -2.5,2.5c-1.21,0 -1.22,-0.86 -1.45,-2h1.95v-3h-3v5h-2v-5h-2v-2h2v-2h-1v-2h1v-1h2v1h1c1.1,0 2,0.9 2,2v2c1.1,0 2,0.9 2,2zM40,22h-1v-1c0,-0.55 0.45,-1 1,-1c0.55,0 1,0.45 1,1c0,0.55 -0.45,1 -1,1zM35,24h1v-2h-1zM35,22v2h1v-2z"></path></g></g> </svg></a></li>
      <li><a class="link" href="https://blog.csdn.net/King_key?type=blog" title="CSDN"><svg xmlns="http://www.w3.org/2000/svg" x="0px" y="0px" width="20" height="20" viewBox="0 0 24 24"> <path d="M6.217 13.408c.447.18 1.379.359 2.132.359.812 0 1.264-.247 1.3-.632.033-.35-.299-.398-1.216-.637-1.267-.342-2.075-.871-1.996-1.717.092-.982 1.286-1.724 3.118-1.724.893 0 1.759.069 2.208.231l-.154 1.238c-.291-.112-1.406-.266-2.16-.266-.765 0-1.16.265-1.188.555-.034.367.363.385 1.356.676 1.345.376 1.933.905 1.856 1.725C11.382 14.18 10.308 15 8.163 15 7.27 15 6.5 14.821 6.076 14.641L6.217 13.408 6.217 13.408zM18.821 9.366c4.884-1.017 5.305.811 5.154 2.428l-.284 2.992h-1.55l.259-2.729c.056-.601.405-1.776-1.281-1.732-.584.016-.873.104-.873.104s-.051.726-.112 1.263l-.294 3.095h-1.52l.302-3.05C18.622 11.736 18.821 9.366 18.821 9.366zM12.653 9.224c.349-.042.884-.084 1.621-.084 1.23 0 2.225.236 2.841.734.553.464.921 1.214.819 2.302-.094 1.012-.57 1.721-1.264 2.159-.635.413-1.434.59-2.637.59-.709 0-1.385-.042-1.9-.126L12.653 9.224 12.653 9.224zM13.669 13.69c.119.025.274.051.582.051 1.231 0 2.098-.668 2.185-1.607.127-1.358-.643-1.832-1.94-1.824-.168 0-.401 0-.525.025L13.669 13.69 13.669 13.69zM5.335 14.813C5.043 14.924 4.439 15 3.595 15c-2.427 0-3.737-1.254-3.583-2.913C.198 10.112 2.139 9 4.264 9c.823 0 1.308.073 1.762.195L5.88 10.526c-.302-.112-1.01-.215-1.583-.215-1.25 0-2.312.41-2.434 1.707-.109 1.16.637 1.714 2.044 1.714.49 0 1.212-.077 1.545-.189C5.452 13.544 5.335 14.813 5.335 14.813z"></path> </svg></a></li>
      
      <li>
        <span id="search-ico" class="ms-Icon--Search">
          <i class="fa-solid fa-magnifying-glass"></i>
        </span>
      </li>
      
      
    </ul>

    <div class="page-top animated fadeInDown">
      <div class="nav">
        
        
        
        
        <li><a  href="https://king-key.github.io/">Home</a></li>
        
        <li><a  href="https://king-key.github.io/tags">Tags</a></li>
        
        <li><a  href="https://king-key.github.io/archive/">Archive</a></li>
        <li><a  href="https://king-key.github.io/about/">About</a></li>
        
        <li><a  href="https://king-key.github.io/link/">Links</a></li>
        
        <li><a href="https://qingkelab.github.io">QingKe.AI</a></li>

      </div>
    </div>

    <div class="footer">
      
      <div class="globe_css">
        <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=21aPpDAfbcdUW3w9EjOGl_8HnMFewhB-9j2dEF73OjM"></script>
      </div>
      
    </div>
  </div>

  <div id="main">
    <div class="search-overlay">
      <button id="close-search" class="close-button">✖</button>
      <div class="search-container">
        <input type="text" id="search" placeholder="Search...">
        <ul class="search-results">
          <h2 class="search-results__header"></h2>
          <ul class="search-results__items"></ul>
        </ul>
      </div>
    </div>

    <div class="autopagerize_page_element">
      <div class="content">
        

<script src="https://king-key.github.io/js/jquery-1.7.2.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script type="text/javascript">
  $(document).ready(function() {
      // 清空目录以防重复
      $("#category").empty();
  
      // 添加文章目录
      $("h2,h3,h4,h5,h6").each(function(i, item) {
          var tag = $(item).prop("tagName").toLowerCase();
          var anchorId = "wow" + i;
          $(item).attr("id", anchorId);
          // 如果是第一个项目，不加 <br>
          if (i === 0) {
              $("#category").append(`<a class="new${tag}" href="#${anchorId}">${$(item).text()}</a>`);
          } else {
              $("#category").append(`<a class="new${tag}" href="#${anchorId}">${$(item).text()}</a><br>`); // 添加 <br> 实现换行
          }
      });
  
      // 设置目录项的缩进
      $(".newh2").css("margin-left", 0);
      $(".newh3").css("margin-left", 20);
      $(".newh4").css("margin-left", 40);
      $(".newh5").css("margin-left", 60);
      $(".newh6").css("margin-left", 80);
  
      // 处理details元素的展开与收缩
      document.querySelectorAll('details summary').forEach(function(summary) {
          summary.addEventListener('click', function() {
              var details = this.nextElementSibling;
              details.style.display = details.style.display === 'none' ? 'block' : 'none';
          });
      });
  });
</script>

<article class="post animated fadeInDown post article-page">
  <h1><a href="https:&#x2F;&#x2F;king-key.github.io&#x2F;Blog&#x2F;2023&#x2F;Q1&#x2F;darknetkuang-jia-gpubian-yi-an-zhuang&#x2F;">darknet框架GPU编译安装</a></h1>
  <div class="info">
    
      <i class="far fa-sun"></i>
      <i>Push time: 2022-12-03 10:08:30&nbsp;&nbsp;</i>
    

    

    <hr>
  </div>
  <!-- toc -->
  <details class="details-2" open>
    <summary tabindex="-1"><a href="javascript:void(0)"><i class="fa-solid fa-list"></i> 文章目录</a></summary>
    <div id="category"></div>
  </details>

  <div class="post-content"><blockquote>
<p>Darknet: Open Source Neural Networks in C</p>
</blockquote>
<span id="continue-reading"></span><h4 id="1-darknetxia-zai">1、darknet下载</h4>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>git clone https://github.com/pjreddie/darknet.git
</span><span>cd darknet
</span></code></pre>
<p>设置<code>makefile</code></p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>gpu=1 
</span><span>cudnn=1 
</span><span>opencv=1
</span></code></pre>
<p>【1】GPU=1;需要设置显卡驱动、cuda</p>
<ul>
<li>使用<code>nvidia-smi</code>查看显卡型号和支持的cuda版本号</li>
</ul>
<p><img src="https://king-key.github.io/Blog/2023/Q1/darknetkuang-jia-gpubian-yi-an-zhuang/./1670033905887.jpg" alt="" /></p>
<ul>
<li><a href="https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=22.04&amp;target_type=runfile_local">nvidia官网</a>下载cuda,以及cudnn</li>
</ul>
<p><img src="https://king-key.github.io/Blog/2023/Q1/darknetkuang-jia-gpubian-yi-an-zhuang/./1670034688635.jpg" alt="" /></p>
<p>安装cuda若提示</p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>Existing package manager installation of the driver found. It is strongly recommended that you remove this before continuing
</span><span>
</span></code></pre>
<p>原因是驱动重复安装，卸载掉其他驱动</p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>dpkg -l | grep Nvidia //查看驱动
</span><span>sudo apt-get purge &quot;nvidia*&quot;  //卸载旧版本驱动
</span></code></pre>
<p>然后再次安装就正常了。成功之后显示</p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>===========
</span><span>= Summary =
</span><span>===========
</span><span>
</span><span>Driver:   Not Selected
</span><span>Toolkit:  Installed in /usr/local/cuda-11.6/
</span><span>
</span><span>Please make sure that
</span><span> -   PATH includes /usr/local/cuda-11.6/bin
</span><span> -   LD_LIBRARY_PATH includes /usr/local/cuda-11.6/lib64, or, add /usr/local/cuda-11.6/lib64 to /etc/ld.so.conf and run ldconfig as root
</span><span>
</span><span>To uninstall the CUDA Toolkit, run cuda-uninstaller in /usr/local/cuda-11.6/bin
</span><span>***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least 510.00 is required for CUDA 11.6 functionality to work.
</span><span>To install the driver using this installer, run the following command, replacing &lt;CudaInstaller&gt; with the name of this run file:
</span><span>    sudo &lt;CudaInstaller&gt;.run --silent --driver
</span><span>
</span><span>Logfile is /var/log/cuda-installer.log
</span></code></pre>
<p>添加cuda到系统路径，<code>vim ~/.zshrv</code></p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>export PATH=/usr/local/cuda-11.6/bin${PATH:+:${PATH}}
</span><span>export LD_LIBRARY_PATH=/usr/local/cuda-11.6/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}
</span></code></pre>
<p>运行<code>source ~/.zshrc</code>让路径生效，此时可以输入命令<code> nvcc -V</code> 验证一下cuda</p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>nvcc: NVIDIA (R) Cuda compiler driver
</span><span>Copyright (c) 2005-2022 NVIDIA Corporation
</span><span>Built on Thu_Feb_10_18:23:41_PST_2022
</span><span>Cuda compilation tools, release 11.6, V11.6.112
</span><span>Build cuda_11.6.r11.6/compiler.30978841_0
</span></code></pre>
<p>【2】cudnn=1</p>
<ul>
<li><a href="https://developer.nvidia.com/rdp/cudnn-download">nvidia官网</a>选择相应版本的cudnn,进行下载（建议下载可解压版本的，方便自己操作）
<img src="https://king-key.github.io/Blog/2023/Q1/darknetkuang-jia-gpubian-yi-an-zhuang/./1670035730632.jpg" alt="" />
将解压出来的cudnn文件copy到cuda路径中(<code>usl/local</code>中会有两个cuda路径，一个带版本号，一个不带，记得是copy到不带版本号的cuda路径中)</li>
</ul>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>sudo cp include/cudnn*.h /usr/local/cuda/include
</span><span>sudo cp lib/libcudnn* /usr/local/cuda/lib64
</span><span>sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
</span></code></pre>
<p>copy完成之后用<code>cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2 </code>验证一下</p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>#define CUDNN_MAJOR 8
</span><span>#define CUDNN_MINOR 7
</span><span>#define CUDNN_PATCHLEVEL 0
</span><span>--
</span><span>#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)
</span></code></pre>
<p>【3】opencv=1</p>
<h4 id="2-darknetbian-yi">2、darknet编译</h4>
<p>由于版本问题，需要先修改几个文件</p>
<ul>
<li>用<code>https://github.com/arnoldfychen/darknet/blob/master/src/convolutional_layer.c </code>直接替换<code>darknet/src/convolutional_laye.c</code>文件，老版本不支持cudnn8以上的</li>
</ul>
<pre data-lang="c" style="background-color:#eff1f5;color:#4f5b66;" class="language-c "><code class="language-c" data-lang="c"><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">convolutional_layer.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">utils.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">batchnorm_layer.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">im2col.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">col2im.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">blas.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">gemm.h</span><span>&quot;
</span><span style="color:#b48ead;">#include </span><span>&lt;</span><span style="color:#a3be8c;">stdio.h</span><span>&gt;
</span><span style="color:#b48ead;">#include </span><span>&lt;</span><span style="color:#a3be8c;">time.h</span><span>&gt;
</span><span>
</span><span style="color:#b48ead;">#define </span><span>PRINT_CUDNN_ALGO </span><span style="color:#d08770;">0
</span><span style="color:#b48ead;">#define </span><span>MEMORY_LIMIT </span><span style="color:#d08770;">2000000000
</span><span>
</span><span style="color:#b48ead;">#ifdef</span><span> AI2
</span><span style="color:#b48ead;">#include </span><span>&quot;</span><span style="color:#a3be8c;">xnor_layer.h</span><span>&quot;
</span><span style="color:#b48ead;">#endif
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">swap_binary</span><span>(convolutional_layer *</span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">float </span><span>*swap = l-&gt;weights;
</span><span>    l-&gt;weights = l-&gt;binary_weights;
</span><span>    l-&gt;binary_weights = swap;
</span><span>
</span><span style="color:#b48ead;">#ifdef</span><span> GPU
</span><span>    swap = l-&gt;weights_gpu;
</span><span>    l-&gt;weights_gpu = l-&gt;binary_weights_gpu;
</span><span>    l-&gt;binary_weights_gpu = swap;
</span><span style="color:#b48ead;">#endif
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">binarize_weights</span><span>(</span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">weights</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">size</span><span>, </span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">binary</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i, f;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(f = </span><span style="color:#d08770;">0</span><span>; f &lt; n; ++f){
</span><span>        </span><span style="color:#b48ead;">float</span><span> mean = </span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; size; ++i){
</span><span>            mean += </span><span style="color:#96b5b4;">fabs</span><span>(weights[f*size + i]);
</span><span>        }
</span><span>        mean = mean / size;
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; size; ++i){
</span><span>            binary[f*size + i] = (weights[f*size + i] &gt; </span><span style="color:#d08770;">0</span><span>) ? mean : -mean;
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">binarize_cpu</span><span>(</span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">input</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">binary</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>        binary[i] = (input[i] &gt; </span><span style="color:#d08770;">0</span><span>) ? </span><span style="color:#d08770;">1 </span><span>: -</span><span style="color:#d08770;">1</span><span>;
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">binarize_input</span><span>(</span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">input</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">size</span><span>, </span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">binary</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i, s;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(s = </span><span style="color:#d08770;">0</span><span>; s &lt; size; ++s){
</span><span>        </span><span style="color:#b48ead;">float</span><span> mean = </span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>            mean += </span><span style="color:#96b5b4;">fabs</span><span>(input[i*size + s]);
</span><span>        }
</span><span>        mean = mean / n;
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>            binary[i*size + s] = (input[i*size + s] &gt; </span><span style="color:#d08770;">0</span><span>) ? mean : -mean;
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">int </span><span style="color:#8fa1b3;">convolutional_out_height</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">return </span><span>(l.</span><span style="color:#bf616a;">h </span><span>+ </span><span style="color:#d08770;">2</span><span>*l.</span><span style="color:#bf616a;">pad </span><span>- l.</span><span style="color:#bf616a;">size</span><span>) / l.</span><span style="color:#bf616a;">stride </span><span>+ </span><span style="color:#d08770;">1</span><span>;
</span><span>}
</span><span>
</span><span style="color:#b48ead;">int </span><span style="color:#8fa1b3;">convolutional_out_width</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">return </span><span>(l.</span><span style="color:#bf616a;">w </span><span>+ </span><span style="color:#d08770;">2</span><span>*l.</span><span style="color:#bf616a;">pad </span><span>- l.</span><span style="color:#bf616a;">size</span><span>) / l.</span><span style="color:#bf616a;">stride </span><span>+ </span><span style="color:#d08770;">1</span><span>;
</span><span>}
</span><span>
</span><span>image </span><span style="color:#8fa1b3;">get_convolutional_image</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">float_to_image</span><span>(l.</span><span style="color:#bf616a;">out_w</span><span>,l.</span><span style="color:#bf616a;">out_h</span><span>,l.</span><span style="color:#bf616a;">out_c</span><span>,l.</span><span style="color:#bf616a;">output</span><span>);
</span><span>}
</span><span>
</span><span>image </span><span style="color:#8fa1b3;">get_convolutional_delta</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">float_to_image</span><span>(l.</span><span style="color:#bf616a;">out_w</span><span>,l.</span><span style="color:#bf616a;">out_h</span><span>,l.</span><span style="color:#bf616a;">out_c</span><span>,l.</span><span style="color:#bf616a;">delta</span><span>);
</span><span>}
</span><span>
</span><span style="color:#b48ead;">static </span><span>size_t </span><span style="color:#8fa1b3;">get_workspace_size</span><span>(layer </span><span style="color:#bf616a;">l</span><span>){
</span><span style="color:#b48ead;">#ifdef</span><span> CUDNN
</span><span>    </span><span style="color:#b48ead;">if</span><span>(gpu_index &gt;= </span><span style="color:#d08770;">0</span><span>){
</span><span>        size_t most = </span><span style="color:#d08770;">0</span><span>;
</span><span>        size_t s = </span><span style="color:#d08770;">0</span><span>;
</span><span>        </span><span style="color:#bf616a;">cudnnGetConvolutionForwardWorkspaceSize</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>                l.</span><span style="color:#bf616a;">srcTensorDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">weightDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">convDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">dstTensorDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">fw_algo</span><span>,
</span><span>                &amp;s);
</span><span>        </span><span style="color:#b48ead;">if </span><span>(s &gt; most) most = s;
</span><span>        </span><span style="color:#bf616a;">cudnnGetConvolutionBackwardFilterWorkspaceSize</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>                l.</span><span style="color:#bf616a;">srcTensorDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">ddstTensorDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">convDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">dweightDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">bf_algo</span><span>,
</span><span>                &amp;s);
</span><span>        </span><span style="color:#b48ead;">if </span><span>(s &gt; most) most = s;
</span><span>        </span><span style="color:#bf616a;">cudnnGetConvolutionBackwardDataWorkspaceSize</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>                l.</span><span style="color:#bf616a;">weightDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">ddstTensorDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">convDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">dsrcTensorDesc</span><span>,
</span><span>                l.</span><span style="color:#bf616a;">bd_algo</span><span>,
</span><span>                &amp;s);
</span><span>        </span><span style="color:#b48ead;">if </span><span>(s &gt; most) most = s;
</span><span>        </span><span style="color:#b48ead;">return</span><span> most;
</span><span>    }
</span><span style="color:#b48ead;">#endif
</span><span>    </span><span style="color:#b48ead;">return </span><span>(size_t)l.</span><span style="color:#bf616a;">out_h</span><span>*l.</span><span style="color:#bf616a;">out_w</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*sizeof(</span><span style="color:#b48ead;">float</span><span>);
</span><span>}
</span><span>
</span><span style="color:#b48ead;">#ifdef</span><span> GPU
</span><span style="color:#b48ead;">#ifdef</span><span> CUDNN
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">cudnn_convolutional_setup</span><span>(layer *</span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#bf616a;">cudnnSetTensor4dDescriptor</span><span>(l-&gt;dsrcTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, l-&gt;batch, l-&gt;c, l-&gt;h, l-&gt;w); 
</span><span>    </span><span style="color:#bf616a;">cudnnSetTensor4dDescriptor</span><span>(l-&gt;ddstTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, l-&gt;batch, l-&gt;out_c, l-&gt;out_h, l-&gt;out_w); 
</span><span>
</span><span>    </span><span style="color:#bf616a;">cudnnSetTensor4dDescriptor</span><span>(l-&gt;srcTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, l-&gt;batch, l-&gt;c, l-&gt;h, l-&gt;w); 
</span><span>    </span><span style="color:#bf616a;">cudnnSetTensor4dDescriptor</span><span>(l-&gt;dstTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, l-&gt;batch, l-&gt;out_c, l-&gt;out_h, l-&gt;out_w); 
</span><span>    </span><span style="color:#bf616a;">cudnnSetTensor4dDescriptor</span><span>(l-&gt;normTensorDesc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, </span><span style="color:#d08770;">1</span><span>, l-&gt;out_c, </span><span style="color:#d08770;">1</span><span>, </span><span style="color:#d08770;">1</span><span>); 
</span><span>
</span><span>    </span><span style="color:#bf616a;">cudnnSetFilter4dDescriptor</span><span>(l-&gt;dweightDesc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, l-&gt;n, l-&gt;c/l-&gt;groups, l-&gt;size, l-&gt;size); 
</span><span>    </span><span style="color:#bf616a;">cudnnSetFilter4dDescriptor</span><span>(l-&gt;weightDesc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, l-&gt;n, l-&gt;c/l-&gt;groups, l-&gt;size, l-&gt;size); 
</span><span>    </span><span style="color:#b48ead;">#if</span><span> CUDNN_MAJOR &gt;= 6
</span><span>    </span><span style="color:#bf616a;">cudnnSetConvolution2dDescriptor</span><span>(l-&gt;convDesc, l-&gt;pad, l-&gt;pad, l-&gt;stride, l-&gt;stride, </span><span style="color:#d08770;">1</span><span>, </span><span style="color:#d08770;">1</span><span>, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT);
</span><span>    </span><span style="color:#b48ead;">#else
</span><span>    </span><span style="color:#bf616a;">cudnnSetConvolution2dDescriptor</span><span>(l-&gt;convDesc, l-&gt;pad, l-&gt;pad, l-&gt;stride, l-&gt;stride, </span><span style="color:#d08770;">1</span><span>, </span><span style="color:#d08770;">1</span><span>, CUDNN_CROSS_CORRELATION);
</span><span>    </span><span style="color:#b48ead;">#endif
</span><span>
</span><span>    </span><span style="color:#b48ead;">#if</span><span> CUDNN_MAJOR &gt;= 7
</span><span>    </span><span style="color:#bf616a;">cudnnSetConvolutionGroupCount</span><span>(l-&gt;convDesc, l-&gt;groups);
</span><span>    </span><span style="color:#b48ead;">#else
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l-&gt;groups &gt; </span><span style="color:#d08770;">1</span><span>){
</span><span>        </span><span style="color:#bf616a;">error</span><span>(&quot;</span><span style="color:#a3be8c;">CUDNN &lt; 7 doesn&#39;t support groups, please upgrade!</span><span>&quot;);
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">#endif
</span><span>    </span><span style="color:#b48ead;">#if</span><span> CUDNN_MAJOR &gt;= 8
</span><span>    </span><span style="color:#b48ead;">int</span><span> returnedAlgoCount;
</span><span>    cudnnConvolutionFwdAlgoPerf_t       fw_results[</span><span style="color:#d08770;">2 </span><span>* CUDNN_CONVOLUTION_FWD_ALGO_COUNT];
</span><span>    cudnnConvolutionBwdDataAlgoPerf_t   bd_results[</span><span style="color:#d08770;">2 </span><span>* CUDNN_CONVOLUTION_BWD_DATA_ALGO_COUNT];
</span><span>    cudnnConvolutionBwdFilterAlgoPerf_t bf_results[</span><span style="color:#d08770;">2 </span><span>* CUDNN_CONVOLUTION_BWD_FILTER_ALGO_COUNT];
</span><span>
</span><span>    </span><span style="color:#bf616a;">cudnnFindConvolutionForwardAlgorithm</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>            l-&gt;srcTensorDesc,
</span><span>            l-&gt;weightDesc,
</span><span>            l-&gt;convDesc,
</span><span>            l-&gt;dstTensorDesc,
</span><span>            CUDNN_CONVOLUTION_FWD_ALGO_COUNT,
</span><span>            &amp;returnedAlgoCount,
</span><span>	    fw_results);
</span><span>    </span><span style="color:#b48ead;">for</span><span>(</span><span style="color:#b48ead;">int</span><span> algoIndex = </span><span style="color:#d08770;">0</span><span>; algoIndex &lt; returnedAlgoCount; ++algoIndex){
</span><span>        </span><span style="color:#b48ead;">#if</span><span> PRINT_CUDNN_ALGO &gt; 0
</span><span>        </span><span style="color:#96b5b4;">printf</span><span>(&quot;</span><span style="color:#a3be8c;">^^^^ </span><span style="color:#d08770;">%s</span><span style="color:#a3be8c;"> for Algo </span><span style="color:#d08770;">%d</span><span style="color:#a3be8c;">: </span><span style="color:#d08770;">%f</span><span style="color:#a3be8c;"> time requiring </span><span style="color:#d08770;">%llu</span><span style="color:#a3be8c;"> memory</span><span style="color:#96b5b4;">\n</span><span>&quot;,
</span><span>               </span><span style="color:#bf616a;">cudnnGetErrorString</span><span>(fw_results[algoIndex].</span><span style="color:#bf616a;">status</span><span>),
</span><span>               fw_results[algoIndex].</span><span style="color:#bf616a;">algo</span><span>, fw_results[algoIndex].</span><span style="color:#bf616a;">time</span><span>,
</span><span>               (</span><span style="color:#b48ead;">unsigned long long</span><span>)fw_results[algoIndex].</span><span style="color:#bf616a;">memory</span><span>);
</span><span>        </span><span style="color:#b48ead;">#endif
</span><span>        </span><span style="color:#b48ead;">if</span><span>( fw_results[algoIndex].</span><span style="color:#bf616a;">memory </span><span>&lt; MEMORY_LIMIT ){
</span><span>            l-&gt;fw_algo = fw_results[algoIndex].</span><span style="color:#bf616a;">algo</span><span>;
</span><span>            </span><span style="color:#b48ead;">break</span><span>;
</span><span>	}
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#bf616a;">cudnnFindConvolutionBackwardDataAlgorithm</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>            l-&gt;weightDesc,
</span><span>            l-&gt;ddstTensorDesc,
</span><span>            l-&gt;convDesc,
</span><span>            l-&gt;dsrcTensorDesc,
</span><span>            CUDNN_CONVOLUTION_BWD_DATA_ALGO_COUNT,
</span><span>            &amp;returnedAlgoCount,
</span><span>            bd_results);
</span><span>    </span><span style="color:#b48ead;">for</span><span>(</span><span style="color:#b48ead;">int</span><span> algoIndex = </span><span style="color:#d08770;">0</span><span>; algoIndex &lt; returnedAlgoCount; ++algoIndex){
</span><span>        </span><span style="color:#b48ead;">#if</span><span> PRINT_CUDNN_ALGO &gt; 0
</span><span>        </span><span style="color:#96b5b4;">printf</span><span>(&quot;</span><span style="color:#a3be8c;">^^^^ </span><span style="color:#d08770;">%s</span><span style="color:#a3be8c;"> for Algo </span><span style="color:#d08770;">%d</span><span style="color:#a3be8c;">: </span><span style="color:#d08770;">%f</span><span style="color:#a3be8c;"> time requiring </span><span style="color:#d08770;">%llu</span><span style="color:#a3be8c;"> memory</span><span style="color:#96b5b4;">\n</span><span>&quot;,
</span><span>               </span><span style="color:#bf616a;">cudnnGetErrorString</span><span>(bd_results[algoIndex].</span><span style="color:#bf616a;">status</span><span>),
</span><span>               bd_results[algoIndex].</span><span style="color:#bf616a;">algo</span><span>, bd_results[algoIndex].</span><span style="color:#bf616a;">time</span><span>,
</span><span>               (</span><span style="color:#b48ead;">unsigned long long</span><span>)bd_results[algoIndex].</span><span style="color:#bf616a;">memory</span><span>);
</span><span>        </span><span style="color:#b48ead;">#endif
</span><span>        </span><span style="color:#b48ead;">if</span><span>( bd_results[algoIndex].</span><span style="color:#bf616a;">memory </span><span>&lt; MEMORY_LIMIT ){
</span><span>            l-&gt;bd_algo = bd_results[algoIndex].</span><span style="color:#bf616a;">algo</span><span>;
</span><span>            </span><span style="color:#b48ead;">break</span><span>;
</span><span>        }
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#bf616a;">cudnnFindConvolutionBackwardFilterAlgorithm</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>            l-&gt;srcTensorDesc,
</span><span>            l-&gt;ddstTensorDesc,
</span><span>            l-&gt;convDesc,
</span><span>            l-&gt;dweightDesc,
</span><span>            CUDNN_CONVOLUTION_BWD_FILTER_ALGO_COUNT,
</span><span>            &amp;returnedAlgoCount,
</span><span>            bf_results);
</span><span>    </span><span style="color:#b48ead;">for</span><span>(</span><span style="color:#b48ead;">int</span><span> algoIndex = </span><span style="color:#d08770;">0</span><span>; algoIndex &lt; returnedAlgoCount; ++algoIndex){
</span><span>        </span><span style="color:#b48ead;">#if</span><span> PRINT_CUDNN_ALGO &gt; 0
</span><span>        </span><span style="color:#96b5b4;">printf</span><span>(&quot;</span><span style="color:#a3be8c;">^^^^ </span><span style="color:#d08770;">%s</span><span style="color:#a3be8c;"> for Algo </span><span style="color:#d08770;">%d</span><span style="color:#a3be8c;">: </span><span style="color:#d08770;">%f</span><span style="color:#a3be8c;"> time requiring </span><span style="color:#d08770;">%llu</span><span style="color:#a3be8c;"> memory</span><span style="color:#96b5b4;">\n</span><span>&quot;,
</span><span>               </span><span style="color:#bf616a;">cudnnGetErrorString</span><span>(bf_results[algoIndex].</span><span style="color:#bf616a;">status</span><span>),
</span><span>               bf_results[algoIndex].</span><span style="color:#bf616a;">algo</span><span>, bf_results[algoIndex].</span><span style="color:#bf616a;">time</span><span>,
</span><span>               (</span><span style="color:#b48ead;">unsigned long long</span><span>)bf_results[algoIndex].</span><span style="color:#bf616a;">memory</span><span>);
</span><span>        </span><span style="color:#b48ead;">#endif
</span><span>        </span><span style="color:#b48ead;">if</span><span>( bf_results[algoIndex].</span><span style="color:#bf616a;">memory </span><span>&lt; MEMORY_LIMIT ){
</span><span>            l-&gt;bf_algo = bf_results[algoIndex].</span><span style="color:#bf616a;">algo</span><span>;
</span><span>            </span><span style="color:#b48ead;">break</span><span>;
</span><span>        }
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#b48ead;">#else
</span><span>
</span><span>    </span><span style="color:#bf616a;">cudnnGetConvolutionForwardAlgorithm</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>            l-&gt;srcTensorDesc,
</span><span>            l-&gt;weightDesc,
</span><span>            l-&gt;convDesc,
</span><span>            l-&gt;dstTensorDesc,
</span><span>            CUDNN_CONVOLUTION_FWD_SPECIFY_WORKSPACE_LIMIT,
</span><span>            </span><span style="color:#d08770;">2000000000</span><span>,
</span><span>            &amp;l-&gt;fw_algo);
</span><span>    </span><span style="color:#bf616a;">cudnnGetConvolutionBackwardDataAlgorithm</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>            l-&gt;weightDesc,
</span><span>            l-&gt;ddstTensorDesc,
</span><span>            l-&gt;convDesc,
</span><span>            l-&gt;dsrcTensorDesc,
</span><span>            CUDNN_CONVOLUTION_BWD_DATA_SPECIFY_WORKSPACE_LIMIT,
</span><span>            </span><span style="color:#d08770;">2000000000</span><span>,
</span><span>            &amp;l-&gt;bd_algo);
</span><span>    </span><span style="color:#bf616a;">cudnnGetConvolutionBackwardFilterAlgorithm</span><span>(</span><span style="color:#bf616a;">cudnn_handle</span><span>(),
</span><span>            l-&gt;srcTensorDesc,
</span><span>            l-&gt;ddstTensorDesc,
</span><span>            l-&gt;convDesc,
</span><span>            l-&gt;dweightDesc,
</span><span>            CUDNN_CONVOLUTION_BWD_FILTER_SPECIFY_WORKSPACE_LIMIT,
</span><span>            </span><span style="color:#d08770;">2000000000</span><span>,
</span><span>            &amp;l-&gt;bf_algo);
</span><span>    </span><span style="color:#b48ead;">#endif
</span><span>}
</span><span style="color:#b48ead;">#endif
</span><span style="color:#b48ead;">#endif
</span><span>
</span><span>convolutional_layer </span><span style="color:#8fa1b3;">make_convolutional_layer</span><span>(</span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">batch</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">h</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">w</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">c</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">groups</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">size</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">stride</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">padding</span><span>, ACTIVATION </span><span style="color:#bf616a;">activation</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">batch_normalize</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">binary</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">xnor</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">adam</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i;
</span><span>    convolutional_layer l = {</span><span style="color:#d08770;">0</span><span>};
</span><span>    l.</span><span style="color:#bf616a;">type </span><span>= CONVOLUTIONAL;
</span><span>
</span><span>    l.</span><span style="color:#bf616a;">groups </span><span>= groups;
</span><span>    l.</span><span style="color:#bf616a;">h </span><span>= h;
</span><span>    l.</span><span style="color:#bf616a;">w </span><span>= w;
</span><span>    l.</span><span style="color:#bf616a;">c </span><span>= c;
</span><span>    l.</span><span style="color:#bf616a;">n </span><span>= n;
</span><span>    l.</span><span style="color:#bf616a;">binary </span><span>= binary;
</span><span>    l.</span><span style="color:#bf616a;">xnor </span><span>= xnor;
</span><span>    l.</span><span style="color:#bf616a;">batch </span><span>= batch;
</span><span>    l.</span><span style="color:#bf616a;">stride </span><span>= stride;
</span><span>    l.</span><span style="color:#bf616a;">size </span><span>= size;
</span><span>    l.</span><span style="color:#bf616a;">pad </span><span>= padding;
</span><span>    l.</span><span style="color:#bf616a;">batch_normalize </span><span>= batch_normalize;
</span><span>
</span><span>    l.</span><span style="color:#bf616a;">weights </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(c/groups*n*size*size, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    l.</span><span style="color:#bf616a;">weight_updates </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(c/groups*n*size*size, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>
</span><span>    l.</span><span style="color:#bf616a;">biases </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    l.</span><span style="color:#bf616a;">bias_updates </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>
</span><span>    l.</span><span style="color:#bf616a;">nweights </span><span>= c/groups*n*size*size;
</span><span>    l.</span><span style="color:#bf616a;">nbiases </span><span>= n;
</span><span>
</span><span>    </span><span style="color:#a7adba;">// float scale = 1./sqrt(size*size*c);
</span><span>    </span><span style="color:#b48ead;">float</span><span> scale = </span><span style="color:#96b5b4;">sqrt</span><span>(</span><span style="color:#d08770;">2.</span><span>/(size*size*c/l.</span><span style="color:#bf616a;">groups</span><span>));
</span><span>    </span><span style="color:#a7adba;">//printf(&quot;convscale %f\n&quot;, scale);
</span><span>    </span><span style="color:#a7adba;">//scale = .02;
</span><span>    </span><span style="color:#a7adba;">//for(i = 0; i &lt; c*n*size*size; ++i) l.weights[i] = scale*rand_uniform(-1, 1);
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">nweights</span><span>; ++i) l.</span><span style="color:#bf616a;">weights</span><span>[i] = scale*</span><span style="color:#bf616a;">rand_normal</span><span>();
</span><span>    </span><span style="color:#b48ead;">int</span><span> out_w = </span><span style="color:#bf616a;">convolutional_out_width</span><span>(l);
</span><span>    </span><span style="color:#b48ead;">int</span><span> out_h = </span><span style="color:#bf616a;">convolutional_out_height</span><span>(l);
</span><span>    l.</span><span style="color:#bf616a;">out_h </span><span>= out_h;
</span><span>    l.</span><span style="color:#bf616a;">out_w </span><span>= out_w;
</span><span>    l.</span><span style="color:#bf616a;">out_c </span><span>= n;
</span><span>    l.</span><span style="color:#bf616a;">outputs </span><span>= l.</span><span style="color:#bf616a;">out_h </span><span>* l.</span><span style="color:#bf616a;">out_w </span><span>* l.</span><span style="color:#bf616a;">out_c</span><span>;
</span><span>    l.</span><span style="color:#bf616a;">inputs </span><span>= l.</span><span style="color:#bf616a;">w </span><span>* l.</span><span style="color:#bf616a;">h </span><span>* l.</span><span style="color:#bf616a;">c</span><span>;
</span><span>
</span><span>    l.</span><span style="color:#bf616a;">output </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">batch</span><span>*l.</span><span style="color:#bf616a;">outputs</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    l.</span><span style="color:#bf616a;">delta  </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">batch</span><span>*l.</span><span style="color:#bf616a;">outputs</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>
</span><span>    l.</span><span style="color:#bf616a;">forward </span><span>= forward_convolutional_layer;
</span><span>    l.</span><span style="color:#bf616a;">backward </span><span>= backward_convolutional_layer;
</span><span>    l.</span><span style="color:#bf616a;">update </span><span>= update_convolutional_layer;
</span><span>    </span><span style="color:#b48ead;">if</span><span>(binary){
</span><span>        l.</span><span style="color:#bf616a;">binary_weights </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">cweights </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, sizeof(</span><span style="color:#b48ead;">char</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">scales </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">if</span><span>(xnor){
</span><span>        l.</span><span style="color:#bf616a;">binary_weights </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">binary_input </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">inputs</span><span>*l.</span><span style="color:#bf616a;">batch</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(batch_normalize){
</span><span>        l.</span><span style="color:#bf616a;">scales </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">scale_updates </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>            l.</span><span style="color:#bf616a;">scales</span><span>[i] = </span><span style="color:#d08770;">1</span><span>;
</span><span>        }
</span><span>
</span><span>        l.</span><span style="color:#bf616a;">mean </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">variance </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>
</span><span>        l.</span><span style="color:#bf616a;">mean_delta </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">variance_delta </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>
</span><span>        l.</span><span style="color:#bf616a;">rolling_mean </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">rolling_variance </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">x </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">batch</span><span>*l.</span><span style="color:#bf616a;">outputs</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">x_norm </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">batch</span><span>*l.</span><span style="color:#bf616a;">outputs</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    }
</span><span>    </span><span style="color:#b48ead;">if</span><span>(adam){
</span><span>        l.</span><span style="color:#bf616a;">m </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">v </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">bias_m </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">scale_m </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">bias_v </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l.</span><span style="color:#bf616a;">scale_v </span><span>= </span><span style="color:#96b5b4;">calloc</span><span>(n, sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    }
</span><span>
</span><span style="color:#b48ead;">#ifdef</span><span> GPU
</span><span>    l.</span><span style="color:#bf616a;">forward_gpu </span><span>= forward_convolutional_layer_gpu;
</span><span>    l.</span><span style="color:#bf616a;">backward_gpu </span><span>= backward_convolutional_layer_gpu;
</span><span>    l.</span><span style="color:#bf616a;">update_gpu </span><span>= update_convolutional_layer_gpu;
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(gpu_index &gt;= </span><span style="color:#d08770;">0</span><span>){
</span><span>        </span><span style="color:#b48ead;">if </span><span>(adam) {
</span><span>            l.</span><span style="color:#bf616a;">m_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">m</span><span>, l.</span><span style="color:#bf616a;">nweights</span><span>);
</span><span>            l.</span><span style="color:#bf616a;">v_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">v</span><span>, l.</span><span style="color:#bf616a;">nweights</span><span>);
</span><span>            l.</span><span style="color:#bf616a;">bias_m_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">bias_m</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">bias_v_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">bias_v</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">scale_m_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">scale_m</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">scale_v_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">scale_v</span><span>, n);
</span><span>        }
</span><span>
</span><span>        l.</span><span style="color:#bf616a;">weights_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">weights</span><span>, l.</span><span style="color:#bf616a;">nweights</span><span>);
</span><span>        l.</span><span style="color:#bf616a;">weight_updates_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">weight_updates</span><span>, l.</span><span style="color:#bf616a;">nweights</span><span>);
</span><span>
</span><span>        l.</span><span style="color:#bf616a;">biases_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">biases</span><span>, n);
</span><span>        l.</span><span style="color:#bf616a;">bias_updates_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">bias_updates</span><span>, n);
</span><span>
</span><span>        l.</span><span style="color:#bf616a;">delta_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">delta</span><span>, l.</span><span style="color:#bf616a;">batch</span><span>*out_h*out_w*n);
</span><span>        l.</span><span style="color:#bf616a;">output_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">output</span><span>, l.</span><span style="color:#bf616a;">batch</span><span>*out_h*out_w*n);
</span><span>
</span><span>        </span><span style="color:#b48ead;">if</span><span>(binary){
</span><span>            l.</span><span style="color:#bf616a;">binary_weights_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">weights</span><span>, l.</span><span style="color:#bf616a;">nweights</span><span>);
</span><span>        }
</span><span>        </span><span style="color:#b48ead;">if</span><span>(xnor){
</span><span>            l.</span><span style="color:#bf616a;">binary_weights_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">weights</span><span>, l.</span><span style="color:#bf616a;">nweights</span><span>);
</span><span>            l.</span><span style="color:#bf616a;">binary_input_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(</span><span style="color:#d08770;">0</span><span>, l.</span><span style="color:#bf616a;">inputs</span><span>*l.</span><span style="color:#bf616a;">batch</span><span>);
</span><span>        }
</span><span>
</span><span>        </span><span style="color:#b48ead;">if</span><span>(batch_normalize){
</span><span>            l.</span><span style="color:#bf616a;">mean_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">mean</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">variance_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">variance</span><span>, n);
</span><span>
</span><span>            l.</span><span style="color:#bf616a;">rolling_mean_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">mean</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">rolling_variance_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">variance</span><span>, n);
</span><span>
</span><span>            l.</span><span style="color:#bf616a;">mean_delta_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">mean</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">variance_delta_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">variance</span><span>, n);
</span><span>
</span><span>            l.</span><span style="color:#bf616a;">scales_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">scales</span><span>, n);
</span><span>            l.</span><span style="color:#bf616a;">scale_updates_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">scale_updates</span><span>, n);
</span><span>
</span><span>            l.</span><span style="color:#bf616a;">x_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">output</span><span>, l.</span><span style="color:#bf616a;">batch</span><span>*out_h*out_w*n);
</span><span>            l.</span><span style="color:#bf616a;">x_norm_gpu </span><span>= </span><span style="color:#bf616a;">cuda_make_array</span><span>(l.</span><span style="color:#bf616a;">output</span><span>, l.</span><span style="color:#bf616a;">batch</span><span>*out_h*out_w*n);
</span><span>        }
</span><span style="color:#b48ead;">#ifdef</span><span> CUDNN
</span><span>        </span><span style="color:#bf616a;">cudnnCreateTensorDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">normTensorDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateTensorDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">srcTensorDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateTensorDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">dstTensorDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateFilterDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">weightDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateTensorDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">dsrcTensorDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateTensorDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">ddstTensorDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateFilterDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">dweightDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnnCreateConvolutionDescriptor</span><span>(&amp;l.</span><span style="color:#bf616a;">convDesc</span><span>);
</span><span>        </span><span style="color:#bf616a;">cudnn_convolutional_setup</span><span>(&amp;l);
</span><span style="color:#b48ead;">#endif
</span><span>    }
</span><span style="color:#b48ead;">#endif
</span><span>    l.</span><span style="color:#bf616a;">workspace_size </span><span>= </span><span style="color:#bf616a;">get_workspace_size</span><span>(l);
</span><span>    l.</span><span style="color:#bf616a;">activation </span><span>= activation;
</span><span>
</span><span>    </span><span style="color:#96b5b4;">fprintf</span><span>(stderr, &quot;</span><span style="color:#a3be8c;">conv  </span><span style="color:#d08770;">%5d %2d</span><span style="color:#a3be8c;"> x</span><span style="color:#d08770;">%2d</span><span style="color:#a3be8c;"> /</span><span style="color:#d08770;">%2d  %4d</span><span style="color:#a3be8c;"> x</span><span style="color:#d08770;">%4d</span><span style="color:#a3be8c;"> x</span><span style="color:#d08770;">%4d</span><span style="color:#a3be8c;">   -&gt;  </span><span style="color:#d08770;">%4d</span><span style="color:#a3be8c;"> x</span><span style="color:#d08770;">%4d</span><span style="color:#a3be8c;"> x</span><span style="color:#d08770;">%4d  %5.3f</span><span style="color:#a3be8c;"> BFLOPs</span><span style="color:#96b5b4;">\n</span><span>&quot;, n, size, size, stride, w, h, c, l.</span><span style="color:#bf616a;">out_w</span><span>, l.</span><span style="color:#bf616a;">out_h</span><span>, l.</span><span style="color:#bf616a;">out_c</span><span>, (</span><span style="color:#d08770;">2.0 </span><span>* l.</span><span style="color:#bf616a;">n </span><span>* l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups </span><span>* l.</span><span style="color:#bf616a;">out_h</span><span>*l.</span><span style="color:#bf616a;">out_w</span><span>)/</span><span style="color:#d08770;">1000000000.</span><span>);
</span><span>
</span><span>    </span><span style="color:#b48ead;">return</span><span> l;
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">denormalize_convolutional_layer</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i, j;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">n</span><span>; ++i){
</span><span>        </span><span style="color:#b48ead;">float</span><span> scale = l.</span><span style="color:#bf616a;">scales</span><span>[i]/</span><span style="color:#96b5b4;">sqrt</span><span>(l.</span><span style="color:#bf616a;">rolling_variance</span><span>[i] + </span><span style="color:#d08770;">.00001</span><span>);
</span><span>        </span><span style="color:#b48ead;">for</span><span>(j = </span><span style="color:#d08770;">0</span><span>; j &lt; l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size</span><span>; ++j){
</span><span>            l.</span><span style="color:#bf616a;">weights</span><span>[i*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size </span><span>+ j] *= scale;
</span><span>        }
</span><span>        l.</span><span style="color:#bf616a;">biases</span><span>[i] -= l.</span><span style="color:#bf616a;">rolling_mean</span><span>[i] * scale;
</span><span>        l.</span><span style="color:#bf616a;">scales</span><span>[i] = </span><span style="color:#d08770;">1</span><span>;
</span><span>        l.</span><span style="color:#bf616a;">rolling_mean</span><span>[i] = </span><span style="color:#d08770;">0</span><span>;
</span><span>        l.</span><span style="color:#bf616a;">rolling_variance</span><span>[i] = </span><span style="color:#d08770;">1</span><span>;
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#a7adba;">/*
</span><span style="color:#a7adba;">void test_convolutional_layer()
</span><span style="color:#a7adba;">{
</span><span style="color:#a7adba;">    convolutional_layer l = make_convolutional_layer(1, 5, 5, 3, 2, 5, 2, 1, LEAKY, 1, 0, 0, 0);
</span><span style="color:#a7adba;">    l.batch_normalize = 1;
</span><span style="color:#a7adba;">    float data[] = {1,1,1,1,1,
</span><span style="color:#a7adba;">        1,1,1,1,1,
</span><span style="color:#a7adba;">        1,1,1,1,1,
</span><span style="color:#a7adba;">        1,1,1,1,1,
</span><span style="color:#a7adba;">        1,1,1,1,1,
</span><span style="color:#a7adba;">        2,2,2,2,2,
</span><span style="color:#a7adba;">        2,2,2,2,2,
</span><span style="color:#a7adba;">        2,2,2,2,2,
</span><span style="color:#a7adba;">        2,2,2,2,2,
</span><span style="color:#a7adba;">        2,2,2,2,2,
</span><span style="color:#a7adba;">        3,3,3,3,3,
</span><span style="color:#a7adba;">        3,3,3,3,3,
</span><span style="color:#a7adba;">        3,3,3,3,3,
</span><span style="color:#a7adba;">        3,3,3,3,3,
</span><span style="color:#a7adba;">        3,3,3,3,3};
</span><span style="color:#a7adba;">    //net.input = data;
</span><span style="color:#a7adba;">    //forward_convolutional_layer(l);
</span><span style="color:#a7adba;">}
</span><span style="color:#a7adba;">*/
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">resize_convolutional_layer</span><span>(convolutional_layer *</span><span style="color:#bf616a;">l</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">w</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">h</span><span>)
</span><span>{
</span><span>    l-&gt;w = w;
</span><span>    l-&gt;h = h;
</span><span>    </span><span style="color:#b48ead;">int</span><span> out_w = </span><span style="color:#bf616a;">convolutional_out_width</span><span>(*l);
</span><span>    </span><span style="color:#b48ead;">int</span><span> out_h = </span><span style="color:#bf616a;">convolutional_out_height</span><span>(*l);
</span><span>
</span><span>    l-&gt;out_w = out_w;
</span><span>    l-&gt;out_h = out_h;
</span><span>
</span><span>    l-&gt;outputs = l-&gt;out_h * l-&gt;out_w * l-&gt;out_c;
</span><span>    l-&gt;inputs = l-&gt;w * l-&gt;h * l-&gt;c;
</span><span>
</span><span>    l-&gt;output = </span><span style="color:#96b5b4;">realloc</span><span>(l-&gt;output, l-&gt;batch*l-&gt;outputs*sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    l-&gt;delta  = </span><span style="color:#96b5b4;">realloc</span><span>(l-&gt;delta,  l-&gt;batch*l-&gt;outputs*sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l-&gt;batch_normalize){
</span><span>        l-&gt;x = </span><span style="color:#96b5b4;">realloc</span><span>(l-&gt;x, l-&gt;batch*l-&gt;outputs*sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>        l-&gt;x_norm  = </span><span style="color:#96b5b4;">realloc</span><span>(l-&gt;x_norm, l-&gt;batch*l-&gt;outputs*sizeof(</span><span style="color:#b48ead;">float</span><span>));
</span><span>    }
</span><span>
</span><span style="color:#b48ead;">#ifdef</span><span> GPU
</span><span>    </span><span style="color:#bf616a;">cuda_free</span><span>(l-&gt;delta_gpu);
</span><span>    </span><span style="color:#bf616a;">cuda_free</span><span>(l-&gt;output_gpu);
</span><span>
</span><span>    l-&gt;delta_gpu =  </span><span style="color:#bf616a;">cuda_make_array</span><span>(l-&gt;delta,  l-&gt;batch*l-&gt;outputs);
</span><span>    l-&gt;output_gpu = </span><span style="color:#bf616a;">cuda_make_array</span><span>(l-&gt;output, l-&gt;batch*l-&gt;outputs);
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l-&gt;batch_normalize){
</span><span>        </span><span style="color:#bf616a;">cuda_free</span><span>(l-&gt;x_gpu);
</span><span>        </span><span style="color:#bf616a;">cuda_free</span><span>(l-&gt;x_norm_gpu);
</span><span>
</span><span>        l-&gt;x_gpu = </span><span style="color:#bf616a;">cuda_make_array</span><span>(l-&gt;output, l-&gt;batch*l-&gt;outputs);
</span><span>        l-&gt;x_norm_gpu = </span><span style="color:#bf616a;">cuda_make_array</span><span>(l-&gt;output, l-&gt;batch*l-&gt;outputs);
</span><span>    }
</span><span style="color:#b48ead;">#ifdef</span><span> CUDNN
</span><span>    </span><span style="color:#bf616a;">cudnn_convolutional_setup</span><span>(l);
</span><span style="color:#b48ead;">#endif
</span><span style="color:#b48ead;">#endif
</span><span>    l-&gt;workspace_size = </span><span style="color:#bf616a;">get_workspace_size</span><span>(*l);
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">add_bias</span><span>(</span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">output</span><span>, </span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">biases</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">batch</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">size</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i,j,b;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(b = </span><span style="color:#d08770;">0</span><span>; b &lt; batch; ++b){
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>            </span><span style="color:#b48ead;">for</span><span>(j = </span><span style="color:#d08770;">0</span><span>; j &lt; size; ++j){
</span><span>                output[(b*n + i)*size + j] += biases[i];
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">scale_bias</span><span>(</span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">output</span><span>, </span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">scales</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">batch</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">size</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i,j,b;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(b = </span><span style="color:#d08770;">0</span><span>; b &lt; batch; ++b){
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>            </span><span style="color:#b48ead;">for</span><span>(j = </span><span style="color:#d08770;">0</span><span>; j &lt; size; ++j){
</span><span>                output[(b*n + i)*size + j] *= scales[i];
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">backward_bias</span><span>(</span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">bias_updates</span><span>, </span><span style="color:#b48ead;">float </span><span>*</span><span style="color:#bf616a;">delta</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">batch</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">n</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">size</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i,b;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(b = </span><span style="color:#d08770;">0</span><span>; b &lt; batch; ++b){
</span><span>        </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; n; ++i){
</span><span>            bias_updates[i] += </span><span style="color:#bf616a;">sum_array</span><span>(delta+size*(i+b*n), size);
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">forward_convolutional_layer</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>, network </span><span style="color:#bf616a;">net</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i, j;
</span><span>
</span><span>    </span><span style="color:#bf616a;">fill_cpu</span><span>(l.</span><span style="color:#bf616a;">outputs</span><span>*l.</span><span style="color:#bf616a;">batch</span><span>, </span><span style="color:#d08770;">0</span><span>, l.</span><span style="color:#bf616a;">output</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l.</span><span style="color:#bf616a;">xnor</span><span>){
</span><span>        </span><span style="color:#bf616a;">binarize_weights</span><span>(l.</span><span style="color:#bf616a;">weights</span><span>, l.</span><span style="color:#bf616a;">n</span><span>, l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size</span><span>, l.</span><span style="color:#bf616a;">binary_weights</span><span>);
</span><span>        </span><span style="color:#bf616a;">swap_binary</span><span>(&amp;l);
</span><span>        </span><span style="color:#bf616a;">binarize_cpu</span><span>(net.</span><span style="color:#bf616a;">input</span><span>, l.</span><span style="color:#bf616a;">c</span><span>*l.</span><span style="color:#bf616a;">h</span><span>*l.</span><span style="color:#bf616a;">w</span><span>*l.</span><span style="color:#bf616a;">batch</span><span>, l.</span><span style="color:#bf616a;">binary_input</span><span>);
</span><span>        net.</span><span style="color:#bf616a;">input </span><span>= l.</span><span style="color:#bf616a;">binary_input</span><span>;
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#b48ead;">int</span><span> m = l.</span><span style="color:#bf616a;">n</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> k = l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> n = l.</span><span style="color:#bf616a;">out_w</span><span>*l.</span><span style="color:#bf616a;">out_h</span><span>;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">batch</span><span>; ++i){
</span><span>        </span><span style="color:#b48ead;">for</span><span>(j = </span><span style="color:#d08770;">0</span><span>; j &lt; l.</span><span style="color:#bf616a;">groups</span><span>; ++j){
</span><span>            </span><span style="color:#b48ead;">float </span><span>*a = l.</span><span style="color:#bf616a;">weights </span><span>+ j*l.</span><span style="color:#bf616a;">nweights</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>            </span><span style="color:#b48ead;">float </span><span>*b = net.</span><span style="color:#bf616a;">workspace</span><span>;
</span><span>            </span><span style="color:#b48ead;">float </span><span>*c = l.</span><span style="color:#bf616a;">output </span><span>+ (i*l.</span><span style="color:#bf616a;">groups </span><span>+ j)*n*m;
</span><span>            </span><span style="color:#b48ead;">float </span><span>*im =  net.</span><span style="color:#bf616a;">input </span><span>+ (i*l.</span><span style="color:#bf616a;">groups </span><span>+ j)*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*l.</span><span style="color:#bf616a;">h</span><span>*l.</span><span style="color:#bf616a;">w</span><span>;
</span><span>
</span><span>            </span><span style="color:#b48ead;">if </span><span>(l.</span><span style="color:#bf616a;">size </span><span>== </span><span style="color:#d08770;">1</span><span>) {
</span><span>                b = im;
</span><span>            } </span><span style="color:#b48ead;">else </span><span>{
</span><span>                </span><span style="color:#bf616a;">im2col_cpu</span><span>(im, l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>, l.</span><span style="color:#bf616a;">h</span><span>, l.</span><span style="color:#bf616a;">w</span><span>, l.</span><span style="color:#bf616a;">size</span><span>, l.</span><span style="color:#bf616a;">stride</span><span>, l.</span><span style="color:#bf616a;">pad</span><span>, b);
</span><span>            }
</span><span>            </span><span style="color:#bf616a;">gemm</span><span>(</span><span style="color:#d08770;">0</span><span>,</span><span style="color:#d08770;">0</span><span>,m,n,k,</span><span style="color:#d08770;">1</span><span>,a,k,b,n,</span><span style="color:#d08770;">1</span><span>,c,n);
</span><span>        }
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l.</span><span style="color:#bf616a;">batch_normalize</span><span>){
</span><span>        </span><span style="color:#bf616a;">forward_batchnorm_layer</span><span>(l, net);
</span><span>    } </span><span style="color:#b48ead;">else </span><span>{
</span><span>        </span><span style="color:#bf616a;">add_bias</span><span>(l.</span><span style="color:#bf616a;">output</span><span>, l.</span><span style="color:#bf616a;">biases</span><span>, l.</span><span style="color:#bf616a;">batch</span><span>, l.</span><span style="color:#bf616a;">n</span><span>, l.</span><span style="color:#bf616a;">out_h</span><span>*l.</span><span style="color:#bf616a;">out_w</span><span>);
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#bf616a;">activate_array</span><span>(l.</span><span style="color:#bf616a;">output</span><span>, l.</span><span style="color:#bf616a;">outputs</span><span>*l.</span><span style="color:#bf616a;">batch</span><span>, l.</span><span style="color:#bf616a;">activation</span><span>);
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l.</span><span style="color:#bf616a;">binary </span><span>|| l.</span><span style="color:#bf616a;">xnor</span><span>) </span><span style="color:#bf616a;">swap_binary</span><span>(&amp;l);
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">backward_convolutional_layer</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>, network </span><span style="color:#bf616a;">net</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i, j;
</span><span>    </span><span style="color:#b48ead;">int</span><span> m = l.</span><span style="color:#bf616a;">n</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> n = l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">size</span><span>*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> k = l.</span><span style="color:#bf616a;">out_w</span><span>*l.</span><span style="color:#bf616a;">out_h</span><span>;
</span><span>
</span><span>    </span><span style="color:#bf616a;">gradient_array</span><span>(l.</span><span style="color:#bf616a;">output</span><span>, l.</span><span style="color:#bf616a;">outputs</span><span>*l.</span><span style="color:#bf616a;">batch</span><span>, l.</span><span style="color:#bf616a;">activation</span><span>, l.</span><span style="color:#bf616a;">delta</span><span>);
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l.</span><span style="color:#bf616a;">batch_normalize</span><span>){
</span><span>        </span><span style="color:#bf616a;">backward_batchnorm_layer</span><span>(l, net);
</span><span>    } </span><span style="color:#b48ead;">else </span><span>{
</span><span>        </span><span style="color:#bf616a;">backward_bias</span><span>(l.</span><span style="color:#bf616a;">bias_updates</span><span>, l.</span><span style="color:#bf616a;">delta</span><span>, l.</span><span style="color:#bf616a;">batch</span><span>, l.</span><span style="color:#bf616a;">n</span><span>, k);
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">batch</span><span>; ++i){
</span><span>        </span><span style="color:#b48ead;">for</span><span>(j = </span><span style="color:#d08770;">0</span><span>; j &lt; l.</span><span style="color:#bf616a;">groups</span><span>; ++j){
</span><span>            </span><span style="color:#b48ead;">float </span><span>*a = l.</span><span style="color:#bf616a;">delta </span><span>+ (i*l.</span><span style="color:#bf616a;">groups </span><span>+ j)*m*k;
</span><span>            </span><span style="color:#b48ead;">float </span><span>*b = net.</span><span style="color:#bf616a;">workspace</span><span>;
</span><span>            </span><span style="color:#b48ead;">float </span><span>*c = l.</span><span style="color:#bf616a;">weight_updates </span><span>+ j*l.</span><span style="color:#bf616a;">nweights</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>
</span><span>            </span><span style="color:#b48ead;">float </span><span>*im  = net.</span><span style="color:#bf616a;">input </span><span>+ (i*l.</span><span style="color:#bf616a;">groups </span><span>+ j)*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*l.</span><span style="color:#bf616a;">h</span><span>*l.</span><span style="color:#bf616a;">w</span><span>;
</span><span>            </span><span style="color:#b48ead;">float </span><span>*imd = net.</span><span style="color:#bf616a;">delta </span><span>+ (i*l.</span><span style="color:#bf616a;">groups </span><span>+ j)*l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>*l.</span><span style="color:#bf616a;">h</span><span>*l.</span><span style="color:#bf616a;">w</span><span>;
</span><span>
</span><span>            </span><span style="color:#b48ead;">if</span><span>(l.</span><span style="color:#bf616a;">size </span><span>== </span><span style="color:#d08770;">1</span><span>){
</span><span>                b = im;
</span><span>            } </span><span style="color:#b48ead;">else </span><span>{
</span><span>                </span><span style="color:#bf616a;">im2col_cpu</span><span>(im, l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>, l.</span><span style="color:#bf616a;">h</span><span>, l.</span><span style="color:#bf616a;">w</span><span>, 
</span><span>                        l.</span><span style="color:#bf616a;">size</span><span>, l.</span><span style="color:#bf616a;">stride</span><span>, l.</span><span style="color:#bf616a;">pad</span><span>, b);
</span><span>            }
</span><span>
</span><span>            </span><span style="color:#bf616a;">gemm</span><span>(</span><span style="color:#d08770;">0</span><span>,</span><span style="color:#d08770;">1</span><span>,m,n,k,</span><span style="color:#d08770;">1</span><span>,a,k,b,k,</span><span style="color:#d08770;">1</span><span>,c,n);
</span><span>
</span><span>            </span><span style="color:#b48ead;">if </span><span>(net.</span><span style="color:#bf616a;">delta</span><span>) {
</span><span>                a = l.</span><span style="color:#bf616a;">weights </span><span>+ j*l.</span><span style="color:#bf616a;">nweights</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>                b = l.</span><span style="color:#bf616a;">delta </span><span>+ (i*l.</span><span style="color:#bf616a;">groups </span><span>+ j)*m*k;
</span><span>                c = net.</span><span style="color:#bf616a;">workspace</span><span>;
</span><span>                </span><span style="color:#b48ead;">if </span><span>(l.</span><span style="color:#bf616a;">size </span><span>== </span><span style="color:#d08770;">1</span><span>) {
</span><span>                    c = imd;
</span><span>                }
</span><span>
</span><span>                </span><span style="color:#bf616a;">gemm</span><span>(</span><span style="color:#d08770;">1</span><span>,</span><span style="color:#d08770;">0</span><span>,n,k,m,</span><span style="color:#d08770;">1</span><span>,a,n,b,k,</span><span style="color:#d08770;">0</span><span>,c,k);
</span><span>
</span><span>                </span><span style="color:#b48ead;">if </span><span>(l.</span><span style="color:#bf616a;">size </span><span>!= </span><span style="color:#d08770;">1</span><span>) {
</span><span>                    </span><span style="color:#bf616a;">col2im_cpu</span><span>(net.</span><span style="color:#bf616a;">workspace</span><span>, l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>, l.</span><span style="color:#bf616a;">h</span><span>, l.</span><span style="color:#bf616a;">w</span><span>, l.</span><span style="color:#bf616a;">size</span><span>, l.</span><span style="color:#bf616a;">stride</span><span>, l.</span><span style="color:#bf616a;">pad</span><span>, imd);
</span><span>                }
</span><span>            }
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">update_convolutional_layer</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>, update_args </span><span style="color:#bf616a;">a</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">float</span><span> learning_rate = a.</span><span style="color:#bf616a;">learning_rate</span><span>*l.</span><span style="color:#bf616a;">learning_rate_scale</span><span>;
</span><span>    </span><span style="color:#b48ead;">float</span><span> momentum = a.</span><span style="color:#bf616a;">momentum</span><span>;
</span><span>    </span><span style="color:#b48ead;">float</span><span> decay = a.</span><span style="color:#bf616a;">decay</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> batch = a.</span><span style="color:#bf616a;">batch</span><span>;
</span><span>
</span><span>    </span><span style="color:#bf616a;">axpy_cpu</span><span>(l.</span><span style="color:#bf616a;">n</span><span>, learning_rate/batch, l.</span><span style="color:#bf616a;">bias_updates</span><span>, </span><span style="color:#d08770;">1</span><span>, l.</span><span style="color:#bf616a;">biases</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>    </span><span style="color:#bf616a;">scal_cpu</span><span>(l.</span><span style="color:#bf616a;">n</span><span>, momentum, l.</span><span style="color:#bf616a;">bias_updates</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>
</span><span>    </span><span style="color:#b48ead;">if</span><span>(l.</span><span style="color:#bf616a;">scales</span><span>){
</span><span>        </span><span style="color:#bf616a;">axpy_cpu</span><span>(l.</span><span style="color:#bf616a;">n</span><span>, learning_rate/batch, l.</span><span style="color:#bf616a;">scale_updates</span><span>, </span><span style="color:#d08770;">1</span><span>, l.</span><span style="color:#bf616a;">scales</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>        </span><span style="color:#bf616a;">scal_cpu</span><span>(l.</span><span style="color:#bf616a;">n</span><span>, momentum, l.</span><span style="color:#bf616a;">scale_updates</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>    }
</span><span>
</span><span>    </span><span style="color:#bf616a;">axpy_cpu</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, -decay*batch, l.</span><span style="color:#bf616a;">weights</span><span>, </span><span style="color:#d08770;">1</span><span>, l.</span><span style="color:#bf616a;">weight_updates</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>    </span><span style="color:#bf616a;">axpy_cpu</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, learning_rate/batch, l.</span><span style="color:#bf616a;">weight_updates</span><span>, </span><span style="color:#d08770;">1</span><span>, l.</span><span style="color:#bf616a;">weights</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>    </span><span style="color:#bf616a;">scal_cpu</span><span>(l.</span><span style="color:#bf616a;">nweights</span><span>, momentum, l.</span><span style="color:#bf616a;">weight_updates</span><span>, </span><span style="color:#d08770;">1</span><span>);
</span><span>}
</span><span>
</span><span>
</span><span>image </span><span style="color:#8fa1b3;">get_convolutional_weight</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>, </span><span style="color:#b48ead;">int </span><span style="color:#bf616a;">i</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> h = l.</span><span style="color:#bf616a;">size</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> w = l.</span><span style="color:#bf616a;">size</span><span>;
</span><span>    </span><span style="color:#b48ead;">int</span><span> c = l.</span><span style="color:#bf616a;">c</span><span>/l.</span><span style="color:#bf616a;">groups</span><span>;
</span><span>    </span><span style="color:#b48ead;">return </span><span style="color:#bf616a;">float_to_image</span><span>(w,h,c,l.</span><span style="color:#bf616a;">weights</span><span>+i*h*w*c);
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">rgbgr_weights</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">n</span><span>; ++i){
</span><span>        image im = </span><span style="color:#bf616a;">get_convolutional_weight</span><span>(l, i);
</span><span>        </span><span style="color:#b48ead;">if </span><span>(im.</span><span style="color:#bf616a;">c </span><span>== </span><span style="color:#d08770;">3</span><span>) {
</span><span>            </span><span style="color:#bf616a;">rgbgr_image</span><span>(im);
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span style="color:#b48ead;">void </span><span style="color:#8fa1b3;">rescale_weights</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>, </span><span style="color:#b48ead;">float </span><span style="color:#bf616a;">scale</span><span>, </span><span style="color:#b48ead;">float </span><span style="color:#bf616a;">trans</span><span>)
</span><span>{
</span><span>    </span><span style="color:#b48ead;">int</span><span> i;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">n</span><span>; ++i){
</span><span>        image im = </span><span style="color:#bf616a;">get_convolutional_weight</span><span>(l, i);
</span><span>        </span><span style="color:#b48ead;">if </span><span>(im.</span><span style="color:#bf616a;">c </span><span>== </span><span style="color:#d08770;">3</span><span>) {
</span><span>            </span><span style="color:#bf616a;">scale_image</span><span>(im, scale);
</span><span>            </span><span style="color:#b48ead;">float</span><span> sum = </span><span style="color:#bf616a;">sum_array</span><span>(im.</span><span style="color:#bf616a;">data</span><span>, im.</span><span style="color:#bf616a;">w</span><span>*im.</span><span style="color:#bf616a;">h</span><span>*im.</span><span style="color:#bf616a;">c</span><span>);
</span><span>            l.</span><span style="color:#bf616a;">biases</span><span>[i] += sum*trans;
</span><span>        }
</span><span>    }
</span><span>}
</span><span>
</span><span>image *</span><span style="color:#8fa1b3;">get_weights</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>)
</span><span>{
</span><span>    image *weights = </span><span style="color:#96b5b4;">calloc</span><span>(l.</span><span style="color:#bf616a;">n</span><span>, sizeof(image));
</span><span>    </span><span style="color:#b48ead;">int</span><span> i;
</span><span>    </span><span style="color:#b48ead;">for</span><span>(i = </span><span style="color:#d08770;">0</span><span>; i &lt; l.</span><span style="color:#bf616a;">n</span><span>; ++i){
</span><span>        weights[i] = </span><span style="color:#bf616a;">copy_image</span><span>(</span><span style="color:#bf616a;">get_convolutional_weight</span><span>(l, i));
</span><span>        </span><span style="color:#bf616a;">normalize_image</span><span>(weights[i]);
</span><span>        </span><span style="color:#a7adba;">/*
</span><span style="color:#a7adba;">           char buff[256];
</span><span style="color:#a7adba;">           sprintf(buff, &quot;filter%d&quot;, i);
</span><span style="color:#a7adba;">           save_image(weights[i], buff);
</span><span style="color:#a7adba;">         */
</span><span>    }
</span><span>    </span><span style="color:#a7adba;">//error(&quot;hey&quot;);
</span><span>    </span><span style="color:#b48ead;">return</span><span> weights;
</span><span>}
</span><span>
</span><span>image *</span><span style="color:#8fa1b3;">visualize_convolutional_layer</span><span>(convolutional_layer </span><span style="color:#bf616a;">l</span><span>, </span><span style="color:#b48ead;">char </span><span>*</span><span style="color:#bf616a;">window</span><span>, image *</span><span style="color:#bf616a;">prev_weights</span><span>)
</span><span>{
</span><span>    image *single_weights = </span><span style="color:#bf616a;">get_weights</span><span>(l);
</span><span>    </span><span style="color:#bf616a;">show_images</span><span>(single_weights, l.</span><span style="color:#bf616a;">n</span><span>, window);
</span><span>
</span><span>    image delta = </span><span style="color:#bf616a;">get_convolutional_image</span><span>(l);
</span><span>    image dc = </span><span style="color:#bf616a;">collapse_image_layers</span><span>(delta, </span><span style="color:#d08770;">1</span><span>);
</span><span>    </span><span style="color:#b48ead;">char</span><span> buff[</span><span style="color:#d08770;">256</span><span>];
</span><span>    </span><span style="color:#96b5b4;">sprintf</span><span>(buff, &quot;</span><span style="color:#d08770;">%s</span><span style="color:#a3be8c;">: Output</span><span>&quot;, window);
</span><span>    </span><span style="color:#a7adba;">//show_image(dc, buff);
</span><span>    </span><span style="color:#a7adba;">//save_image(dc, buff);
</span><span>    </span><span style="color:#bf616a;">free_image</span><span>(dc);
</span><span>    </span><span style="color:#b48ead;">return</span><span> single_weights;
</span><span>}
</span><span>
</span></code></pre>
<ul>
<li>修改<code>/src/gemm.c</code>中的<code>cudaThreadSynchronize</code>为<code>cudaDeviceSynchronize</code></li>
<li>Makefile中添加,并删除掉低版本的信息</li>
</ul>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>-gencode arch=compute_70,code=[sm_70,compute_70] \
</span><span>-gencode arch=compute_75,code=[sm_75,compute_75] \
</span><span>-gencode arch=compute_86,code=[sm_86,compute_86]
</span></code></pre>
<p>最后，用<code>make</code>命令编译</p>
<h4 id="3-bian-yi-chu-cuo">3、编译出错</h4>
<p><code>/bin/sh: 1: nvcc: not found </code>
sudo</p>
<p>修改<code>Makefile</code>中<code>nvcc</code>的路径</p>
<pre data-lang="shell" style="background-color:#eff1f5;color:#4f5b66;" class="language-shell "><code class="language-shell" data-lang="shell"><span>NVCC=/usr/local/cuda/bin/nvcc
</span></code></pre>
</div>
  <div class="post-footer">
    <div class="meta">
      <div class="info">
        <!-- 这里可以添加额外的 meta 信息 -->
        
        
        
    
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <div class="post-navigation">
          
          <div class="nav-item prev">
            
              
              
              <a href="https:&#x2F;&#x2F;king-key.github.io&#x2F;Blog&#x2F;2023&#x2F;Q1&#x2F;darknet-yolo&#x2F;" class="nav-link">
                <i class="fas fa-chevron-left"></i>
                <span class="nav-title">darknet测试yolo</span>
              </a>
            
          </div>
      
          
          <div class="nav-item next">
            
              
              
              <a href="https:&#x2F;&#x2F;king-key.github.io&#x2F;Essay&#x2F;2022&#x2F;ling-yun-xiu-jing-cang-lan&#x2F;" class="nav-link">
                <span class="nav-title">凌云岫 敬沧澜</span>
                <i class="fas fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      </div>
    </div>
  </div>
</article>










<!-- CSS -->

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.10.0/font/bootstrap-icons.css">
<style>
  .post-navigation {
    margin: 3rem 0;
    display: flex;
    justify-content: space-between;
    border-top: 1px solid #eee;
    padding-top: 2rem;
  }

  .nav-item {
    flex: 1;
    max-width: 45%;
  }

  .nav-item.prev {
    text-align: left;
    padding-right: 1rem;
  }

  .nav-item.next {
    text-align: right;
    padding-left: 1rem;
  }

  .nav-link {
    color: #2c3e50;
    display: inline-flex;
    align-items: center;
    gap: 0.5rem;
    transition: color 0.3s ease;
  }

  .nav-link:hover {
    color: #3498db;
    text-decoration: none;
  }

  .nav-disabled {
    color: #95a5a6;
    font-style: italic;
  }

  .nav-title {
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }

  @media (max-width: 768px) {
    .nav-title {
      max-width: 30vw;
    }
  }
</style>
  


      </div>
    </div>
  </div>
</body>

</html>